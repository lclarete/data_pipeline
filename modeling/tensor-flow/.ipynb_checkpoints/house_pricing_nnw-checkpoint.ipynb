{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicing price houses with keras\n",
    "* Following tutorial: https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housepricedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0     8450            7            5          856         2         1   \n",
       "1     9600            6            8         1262         2         0   \n",
       "2    11250            7            5          920         2         1   \n",
       "3     9550            7            5          756         1         0   \n",
       "4    14260            8            5         1145         2         1   \n",
       "\n",
       "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0             3             8           0         548                 1  \n",
       "1             3             6           1         460                 1  \n",
       "2             3             6           1         608                 1  \n",
       "3             3             7           1         642                 0  \n",
       "4             4             9           1         836                 1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    913\n",
      "1    535\n",
      "2     12\n",
      "Name: HalfBath, dtype: int64-----0    690\n",
      "1    650\n",
      "2    115\n",
      "3      5\n",
      "Name: Fireplaces, dtype: int64-----0    732\n",
      "1    728\n",
      "Name: AboveMedianPrice, dtype: int64-----"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].mean() < 1:\n",
    "        print(df[i].value_counts(), end='-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.83</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.58</td>\n",
       "      <td>1057.43</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.87</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>472.98</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.26</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.11</td>\n",
       "      <td>438.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>213.80</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>795.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>334.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>991.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>480.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1298.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>576.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6110.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1418.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "count    1460.00      1460.00      1460.00      1460.00   1460.00   1460.00   \n",
       "mean    10516.83         6.10         5.58      1057.43      1.57      0.38   \n",
       "std      9981.26         1.38         1.11       438.71      0.55      0.50   \n",
       "min      1300.00         1.00         1.00         0.00      0.00      0.00   \n",
       "25%      7553.50         5.00         5.00       795.75      1.00      0.00   \n",
       "50%      9478.50         6.00         5.00       991.50      2.00      0.00   \n",
       "75%     11601.50         7.00         6.00      1298.25      2.00      1.00   \n",
       "max    215245.00        10.00         9.00      6110.00      3.00      2.00   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "count       1460.00       1460.00     1460.00     1460.00            1460.0  \n",
       "mean           2.87          6.52        0.61      472.98               0.5  \n",
       "std            0.82          1.63        0.64      213.80               0.5  \n",
       "min            0.00          2.00        0.00        0.00               0.0  \n",
       "25%            2.00          5.00        0.00      334.50               0.0  \n",
       "50%            3.00          6.00        1.00      480.00               0.0  \n",
       "75%            3.00          7.00        1.00      576.00               1.0  \n",
       "max            8.00         14.00        3.00     1418.00               1.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x137f3b630>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "df.drop(['LotArea', 'TotalBsmtSF', 'GarageArea'], axis=1).boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:10]\n",
    "y = dataset[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_scale, y, \n",
    "                                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, \n",
    "                                                y_val_and_test, \n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \n",
    "      X_val.shape, \n",
    "      X_test.shape, \n",
    "      y_train.shape, \n",
    "      y_val.shape, \n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Keras - step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1460/1460 [==============================] - 1s 925us/step - loss: 592654.7229\n",
      "Epoch 2/10\n",
      "1460/1460 [==============================] - 0s 252us/step - loss: 114.6233\n",
      "Epoch 3/10\n",
      "1460/1460 [==============================] - 1s 435us/step - loss: 83.7939\n",
      "Epoch 4/10\n",
      "1460/1460 [==============================] - 0s 303us/step - loss: 101.8733\n",
      "Epoch 5/10\n",
      "1460/1460 [==============================] - 1s 344us/step - loss: 26.3949\n",
      "Epoch 6/10\n",
      "1460/1460 [==============================] - 0s 338us/step - loss: 17.7497\n",
      "Epoch 7/10\n",
      "1460/1460 [==============================] - 0s 310us/step - loss: 10.7224\n",
      "Epoch 8/10\n",
      "1460/1460 [==============================] - 0s 320us/step - loss: 49.0976\n",
      "Epoch 9/10\n",
      "1460/1460 [==============================] - 0s 270us/step - loss: 234.1173\n",
      "Epoch 10/10\n",
      "1460/1460 [==============================] - 0s 281us/step - loss: 1537.4323\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "0.36115173553222935\n",
      "22.91947909562921\n"
     ]
    }
   ],
   "source": [
    "# 1: SPECIFY THE ARCHITECTURE -- REGRESSION\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(32, activation='relu', input_shape=(10,)),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid'),\n",
    "# ])\n",
    "\n",
    "# Instantiate the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, \n",
    "                activation='relu', \n",
    "                input_shape=(10,)))\n",
    "\n",
    "# Add a first layer\n",
    "model.add(Dense(32,\n",
    "               activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 2: COMPILE THE MODEL -- REGRESSION\n",
    "model.compile(optimizer='adam',\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "# 3: FIT THE MODEL\n",
    "model.fit(X, y,\n",
    "          batch_size=8,\n",
    "          epochs=10\n",
    "#           validation_data=(X_val, Y_val)\n",
    "         )\n",
    "\n",
    "# 4: PREDICT\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 5: EVALUATE\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "# Calculate the error\n",
    "print(mean_squared_error(y_pred, y))\n",
    "\n",
    "# Visualize the evaluation results\n",
    "# plt.plot(hist.history['loss'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(hist.history['acc'])\n",
    "# plt.plot(hist.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# 6: SAVE AND RELOAD THE MODEL\n",
    "from keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "predictions = my_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,215\n",
      "Trainable params: 2,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Compile the model -- classification\n",
    "\n",
    "# # # Compile the model -- classification\n",
    "# # model.compile(optimizer='adam',\n",
    "# #               loss='categorical_crossentropy', # also called log loss\n",
    "# #               # loss='binary_crossentropy',\n",
    "# #               # print the 'acc: 0.7789' at the end of each epoch\n",
    "# #              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(50, \n",
    "#                 activation='relu', \n",
    "#                 input_shape=(10,)))\n",
    "\n",
    "# model.add(Dense(32,\n",
    "#                activation='relu'))\n",
    "\n",
    "# # add softmax as an activation from within the output layer\n",
    "# predictions sum to 1 and so can be interpret the output as probabilities\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# # Compile the model -- regression\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy', # also called log loss\n",
    "#               # loss='binary_crossentropy',\n",
    "#              )\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(X_train, y_train,\n",
    "#           batch_size=8,\n",
    "#           epochs=10\n",
    "# #           validation_data=(X_val, Y_val)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras NN - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = X.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "def nn_model(input_shape=input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(168, activation='relu', input_shape=input_shape),\n",
    "        Dense(168, activation='relu'),\n",
    "        Dense(2, activation='relu')])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model2(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.001000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: nan   \n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 95us/step - loss: nan\n",
      "Epoch 3/30\n",
      " 544/1460 [==========>...................] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liviaclarete/.pyenv/versions/dataAnalysis/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 102us/step - loss: nan\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: nan\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: nan\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: nan\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 99us/step - loss: nan\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 102us/step - loss: nan\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 90us/step - loss: nan\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: nan\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: nan\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 97us/step - loss: nan\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 273us/step - loss: nan\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 164us/step - loss: nan\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 104us/step - loss: nan\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 105us/step - loss: nan\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: nan\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: nan\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: nan\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 98us/step - loss: nan\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 121us/step - loss: nan\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 136us/step - loss: nan\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 123us/step - loss: nan\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 107us/step - loss: nan\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 166us/step - loss: nan\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 129us/step - loss: nan\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: nan\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: nan\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 106us/step - loss: nan\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 230us/step - loss: nan\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: 2858.3414\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 85us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 79us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 74us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 79us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 87us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 146us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 88us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 139us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 132us/step - loss: 0.5000 0s - loss: 0.5\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 141us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 92us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 88us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 109us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 106us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 186us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 111us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 95us/step - loss: 0.5000\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: 12325.7986\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 97us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 92us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 91us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 99us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 89us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 104us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 89us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 105us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 89us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 103us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 115us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 109us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 162us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 99us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 217us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 156us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 104us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 194us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 104us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 130us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 176us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 134us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 127us/step - loss: 0.5000\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: 226515.6856\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 102us/step - loss: 0.4006\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 88us/step - loss: 0.3830\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 95us/step - loss: 0.3771\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 89us/step - loss: 0.3752\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 99us/step - loss: 0.3746\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.3744\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 98us/step - loss: 0.3744\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 92us/step - loss: 0.3744\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.3744\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 79us/step - loss: 0.3743\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 131us/step - loss: 0.3744\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 117us/step - loss: 0.3744\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 76us/step - loss: 0.3744\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 83us/step - loss: 0.3744\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 95us/step - loss: 0.3744\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.3744\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 72us/step - loss: 0.3743\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.3744\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 76us/step - loss: 0.3744\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 85us/step - loss: 0.3744\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 97us/step - loss: 0.3743\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 124us/step - loss: 0.3744\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 181us/step - loss: 0.3744\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 135us/step - loss: 0.3744\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 126us/step - loss: 0.3744\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 111us/step - loss: 0.3744\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.3744\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 106us/step - loss: 0.3743\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 83us/step - loss: 0.3743\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: 0.5073\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 108us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 85us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 88us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 92us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 87us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 91us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 90us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 104us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 157us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 124us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 120us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 134us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 112us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 87us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 92us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 84us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 85us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 91us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 87us/step - loss: 0.5000\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 2s 1ms/step - loss: 151323.7438\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 73us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 77us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 71us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 73us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 75us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 80us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 78us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 79us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 84us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 76us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 75us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 77us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 77us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 80us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 84us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 84us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 78us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 83us/step - loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# import optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# early callbacks definition\n",
    "# optimization will automatically stop when it is no longer helpful\n",
    "early_stop_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# list of learning rates\n",
    "lr_test = [.001, .01, 1]\n",
    "for lr in lr_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    # import the model\n",
    "    model1 = nn_model()\n",
    "    model2 = nn_model2()\n",
    "    # define optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    # compile the model\n",
    "    model1.compile(optimizer=my_optimizer, loss='mean_squared_error')\n",
    "    model2.compile(optimizer=my_optimizer, loss='mean_squared_error')    \n",
    "    # fit the model\n",
    "    model1_fit = model1.fit(X, target, \n",
    "              validation_split=3,\n",
    "              # note that callbacks receives a list\n",
    "              callbacks=[early_stop_monitor],\n",
    "              epochs=30\n",
    "             )\n",
    "    model2_fit = model2.fit(X, target, \n",
    "          validation_split=3,\n",
    "          # note that callbacks receives a list\n",
    "          callbacks=[early_stop_monitor],\n",
    "          epochs=30\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.plot(model1_fit.history['loss'], 'r', model2_fit.history['loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataAnalysis",
   "language": "python",
   "name": "dataanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
