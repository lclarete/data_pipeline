{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "* https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/\n",
    "\n",
    "* https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "References:\n",
    "* https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "# tokenize data: can use one_hot or Tokenizer\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# padding the arrays with zeros\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # modeling\n",
    "# from keras.models import Sequential # beginners API\n",
    "# from keras.models import Model # advanced\n",
    "\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers.embeddings import Embedding\n",
    "\n",
    "# from keras.models import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import list of text\n",
    "corpus = [\n",
    "    # Positive Reviews\n",
    "\n",
    "    'This is an excellent movie',\n",
    "    'The move was fantastic I like it',\n",
    "    'You should watch it is brilliant',\n",
    "    'Exceptionally good',\n",
    "    'Wonderfully directed and executed I like it',\n",
    "    'Its a fantastic series',\n",
    "    'Never watched such a brillent movie',\n",
    "    'It is a Wonderful movie',\n",
    "\n",
    "    # Negtive Reviews\n",
    "\n",
    "    \"horrible acting\",\n",
    "    'waste of money',\n",
    "    'pathetic picture',\n",
    "    'It was very boring',\n",
    "    'I did not like the movie',\n",
    "    'The movie was horrible',\n",
    "    'I will not recommend',\n",
    "    'The acting is pathetic'\n",
    "]\n",
    "\n",
    "# create an array of labels: 1 for positive and 0 for negative\n",
    "sentiments = np.array(np.ones(len(corpus)//2).tolist() + \n",
    "                      np.zeros(len(corpus)//2).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode my vectos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  1, 35,  5, 20,  0,  0],\n",
       "       [12, 31, 21, 10, 29, 41, 44],\n",
       "       [25, 47, 27, 44,  1, 47,  0],\n",
       "       [22,  4,  0,  0,  0,  0,  0],\n",
       "       [35, 16, 45, 19, 29, 41, 44],\n",
       "       [38, 34, 10,  7,  0,  0,  0],\n",
       "       [42, 33, 25, 34,  1, 20,  0],\n",
       "       [44,  1, 34, 40, 20,  0,  0],\n",
       "       [23,  8,  0,  0,  0,  0,  0],\n",
       "       [35, 10,  9,  0,  0,  0,  0],\n",
       "       [30, 36,  0,  0,  0,  0,  0],\n",
       "       [44, 21, 34, 28,  0,  0,  0],\n",
       "       [29, 46, 22, 41, 12, 20,  0],\n",
       "       [12, 20, 21, 23,  0,  0,  0],\n",
       "       [29, 10, 22,  4,  0,  0,  0],\n",
       "       [12,  8,  1, 30,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing: create encoded arrays\n",
    "\n",
    "from word_embedding_preprocessing import padding_encoded_vector_func\n",
    "\n",
    "padded_sentences = padding_encoded_vector_func(corpus, extra_size=5)\n",
    "padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained vectors: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_glove import load_embedding_matrix\n",
    "\n",
    "path_glove = '/Users/liviaclarete/Downloads/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "embedding_matrix = load_embedding_matrix(corpus, vocab_size, path_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpreting the model.summary()__\n",
    "\n",
    "Params #: number of trainable parameters from each layer\n",
    "\n",
    "* embedding_14: product of the vocabulary size (50) and the number of dimentional vector (20): 50 * 20 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 7, 20)             1000      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 1,141\n",
      "Trainable params: 1,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from word_embedding_model import create_sequencial_model\n",
    "from word_embedding_model import create_functional_model\n",
    "\n",
    "# instantiate the model sequencial model\n",
    "learn_rate = 0.0001\n",
    "model = create_sequencial_model(corpus, 50, learn_rate)\n",
    "model.summary()\n",
    "\n",
    "model2 = create_functional_model(corpus, 50, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.4375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6912 - acc: 0.5625\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - acc: 0.5625\n",
      "Loss: 1\n",
      "Accuracy:  0.5625\n"
     ]
    }
   ],
   "source": [
    "# SEQUENCIAL MODEL\n",
    "\n",
    "# fit the models\n",
    "\n",
    "epochs = 2\n",
    "model.fit(\n",
    "    # array of encoded padded array (completed with zeros)\n",
    "    padded_sentences, \n",
    "    # labels\n",
    "    sentiments, \n",
    "    # number of epochs\n",
    "    epochs=epochs, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "# evaluate the models\n",
    "# in this case, the evaluation is being evaluated with the\n",
    "# same data. In real world it should be different\n",
    "\n",
    "loss, accuracy = model.evaluate(\n",
    "    # padded array for the test set\n",
    "    padded_sentences, \n",
    "    # labels for the test set\n",
    "    sentiments, \n",
    "    verbose=1)\n",
    "\n",
    "print('Loss:', round(loss))\n",
    "\n",
    "# In the output, that model accuracy is 1.00 i.e. 100 percent.\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7081 - acc: 0.5625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6840 - acc: 0.5625\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6908 - acc: 0.5625\n",
      "Loss: 1\n",
      "Accuracy:  0.5625\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONAL MODELS\n",
    "\n",
    "# fit the models\n",
    "model2.fit(\n",
    "    # array of encoded padded array (completed with zeros)\n",
    "    padded_sentences, \n",
    "    # labels\n",
    "    sentiments, \n",
    "    # number of epochs\n",
    "    epochs=epochs, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "# evaluate the models\n",
    "# in this case, the evaluation is being evaluated with the\n",
    "# same data. In real world it should be different\n",
    "\n",
    "loss, accuracy = model.evaluate(\n",
    "    # padded array for the test set\n",
    "    padded_sentences, \n",
    "    # labels for the test set\n",
    "    sentiments, \n",
    "    verbose=1)\n",
    "\n",
    "print('Loss:', round(loss))\n",
    "\n",
    "# In the output, that model accuracy is 1.00 i.e. 100 percent.\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coca3",
   "language": "python",
   "name": "coca3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
