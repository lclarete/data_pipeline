{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicing price houses with keras\n",
    "* Following tutorial: https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housepricedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0     8450            7            5          856         2         1   \n",
       "1     9600            6            8         1262         2         0   \n",
       "2    11250            7            5          920         2         1   \n",
       "3     9550            7            5          756         1         0   \n",
       "4    14260            8            5         1145         2         1   \n",
       "\n",
       "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0             3             8           0         548                 1  \n",
       "1             3             6           1         460                 1  \n",
       "2             3             6           1         608                 1  \n",
       "3             3             7           1         642                 0  \n",
       "4             4             9           1         836                 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    913\n",
      "1    535\n",
      "2     12\n",
      "Name: HalfBath, dtype: int64-----0    690\n",
      "1    650\n",
      "2    115\n",
      "3      5\n",
      "Name: Fireplaces, dtype: int64-----0    732\n",
      "1    728\n",
      "Name: AboveMedianPrice, dtype: int64-----"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].mean() < 1:\n",
    "        print(df[i].value_counts(), end='-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.83</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.58</td>\n",
       "      <td>1057.43</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.87</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>472.98</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.26</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.11</td>\n",
       "      <td>438.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>213.80</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>795.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>334.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>991.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>480.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1298.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>576.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6110.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1418.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "count    1460.00      1460.00      1460.00      1460.00   1460.00   1460.00   \n",
       "mean    10516.83         6.10         5.58      1057.43      1.57      0.38   \n",
       "std      9981.26         1.38         1.11       438.71      0.55      0.50   \n",
       "min      1300.00         1.00         1.00         0.00      0.00      0.00   \n",
       "25%      7553.50         5.00         5.00       795.75      1.00      0.00   \n",
       "50%      9478.50         6.00         5.00       991.50      2.00      0.00   \n",
       "75%     11601.50         7.00         6.00      1298.25      2.00      1.00   \n",
       "max    215245.00        10.00         9.00      6110.00      3.00      2.00   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "count       1460.00       1460.00     1460.00     1460.00            1460.0  \n",
       "mean           2.87          6.52        0.61      472.98               0.5  \n",
       "std            0.82          1.63        0.64      213.80               0.5  \n",
       "min            0.00          2.00        0.00        0.00               0.0  \n",
       "25%            2.00          5.00        0.00      334.50               0.0  \n",
       "50%            3.00          6.00        1.00      480.00               0.0  \n",
       "75%            3.00          7.00        1.00      576.00               1.0  \n",
       "max            8.00         14.00        3.00     1418.00               1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12ef77588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "df.drop(['LotArea', 'TotalBsmtSF', 'GarageArea'], axis=1).boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:10]\n",
    "y = dataset[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_scale, y, \n",
    "                                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, \n",
    "                                                y_val_and_test, \n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \n",
    "      X_val.shape, \n",
    "      X_test.shape, \n",
    "      y_train.shape, \n",
    "      y_val.shape, \n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Keras - step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1460/1460 [==============================] - 1s 477us/step - loss: 15289.2236\n",
      "Epoch 2/10\n",
      "1460/1460 [==============================] - 0s 214us/step - loss: 57551.9801\n",
      "Epoch 3/10\n",
      "1460/1460 [==============================] - 0s 200us/step - loss: 154.2894\n",
      "Epoch 4/10\n",
      "1460/1460 [==============================] - 0s 180us/step - loss: 127.0800\n",
      "Epoch 5/10\n",
      "1460/1460 [==============================] - 0s 171us/step - loss: 76.4425\n",
      "Epoch 6/10\n",
      "1460/1460 [==============================] - 0s 194us/step - loss: 299.6874\n",
      "Epoch 7/10\n",
      "1460/1460 [==============================] - 0s 327us/step - loss: 297.4432\n",
      "Epoch 8/10\n",
      "1460/1460 [==============================] - 0s 159us/step - loss: 76.0726\n",
      "Epoch 9/10\n",
      "1460/1460 [==============================] - 0s 199us/step - loss: 17.2776\n",
      "Epoch 10/10\n",
      "1460/1460 [==============================] - 0s 164us/step - loss: 205.8314\n",
      "219/219 [==============================] - 0s 147us/step\n",
      "0.5732971427103156\n",
      "9.809582421286581\n"
     ]
    }
   ],
   "source": [
    "# 1: SPECIFY THE ARCHITECTURE -- REGRESSION\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(32, activation='relu', input_shape=(10,)),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid'),\n",
    "# ])\n",
    "\n",
    "# Instantiate the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, \n",
    "                activation='relu', \n",
    "                input_shape=(10,)))\n",
    "\n",
    "# Add a first layer\n",
    "model.add(Dense(32,\n",
    "               activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 2: COMPILE THE MODEL -- REGRESSION\n",
    "model.compile(optimizer='adam',\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "# 3: FIT THE MODEL\n",
    "model.fit(X, y,\n",
    "          batch_size=8,\n",
    "          epochs=10\n",
    "#           validation_data=(X_val, Y_val)\n",
    "         )\n",
    "\n",
    "# 4: PREDICT\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 5: EVALUATE\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "# Calculate the error\n",
    "print(mean_squared_error(y_pred, y))\n",
    "\n",
    "# Visualize the evaluation results\n",
    "# plt.plot(hist.history['loss'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(hist.history['acc'])\n",
    "# plt.plot(hist.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# 6: SAVE AND RELOAD THE MODEL\n",
    "from keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "predictions = my_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,215\n",
      "Trainable params: 2,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Compile the model -- classification\n",
    "\n",
    "# # # Compile the model -- classification\n",
    "# # model.compile(optimizer='adam',\n",
    "# #               loss='categorical_crossentropy', # also called log loss\n",
    "# #               # loss='binary_crossentropy',\n",
    "# #               # print the 'acc: 0.7789' at the end of each epoch\n",
    "# #              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(50, \n",
    "#                 activation='relu', \n",
    "#                 input_shape=(10,)))\n",
    "\n",
    "# model.add(Dense(32,\n",
    "#                activation='relu'))\n",
    "\n",
    "# # add softmax as an activation from within the output layer\n",
    "# predictions sum to 1 and so can be interpret the output as probabilities\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# # Compile the model -- regression\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy', # also called log loss\n",
    "#               # loss='binary_crossentropy',\n",
    "#              )\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(X_train, y_train,\n",
    "#           batch_size=8,\n",
    "#           epochs=10\n",
    "# #           validation_data=(X_val, Y_val)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras NN - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = X.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "def nn_model(input_shape=input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(168, activation='relu', input_shape=input_shape),\n",
    "        Dense(168, activation='relu'),\n",
    "        Dense(2, activation='relu')])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model2(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.001000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 0s 265us/step - loss: 3188.1527\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 57us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 57us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "  32/1460 [..............................] - ETA: 0s - loss: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liviaclarete/.pyenv/versions/dataAnalysis/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 72us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 64us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 57us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 66us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 63us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 97us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 184us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 100us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 63us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 64us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 110us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 68us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 72us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 107us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 96us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 77us/step - loss: 0.5000\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 0s 184us/step - loss: 4440.4308\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 50us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 64us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 39us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 65us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 115us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 80us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 65us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 80us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 81us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 43us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 50us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 69us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 70us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 46us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 0.5000\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 0s 307us/step - loss: 5521.5062\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 66us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 71us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 53us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 63us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000 0s - loss: 0.500\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 124us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 93us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 101us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 75us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 0s 249us/step - loss: nan \n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: nan\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 52us/step - loss: nan\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 42us/step - loss: nan\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 43us/step - loss: nan\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: nan\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: nan\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 48us/step - loss: nan\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 68us/step - loss: nan\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 78us/step - loss: nan\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 69us/step - loss: nan\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: nan\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 53us/step - loss: nan\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 121us/step - loss: nan\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 67us/step - loss: nan\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 66us/step - loss: nan\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 71us/step - loss: nan\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 65us/step - loss: nan\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: nan\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: nan\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 73us/step - loss: nan\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 65us/step - loss: nan\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: nan\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 45us/step - loss: nan\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 42us/step - loss: nan\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 41us/step - loss: nan\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: nan\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 1s 378us/step - loss: 17996.4425\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 76us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 64us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 63us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 68us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 66us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 68us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 91us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 55us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 150us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 71us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 98us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 103us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 94us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 86us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 98us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 69us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 66us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 124us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 106us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 78us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 59us/step - loss: 0.5000\n",
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 0s 254us/step - loss: 3.6265\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: 0.5000\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 70us/step - loss: 0.5000\n",
      "Epoch 4/30\n",
      "1460/1460 [==============================] - 0s 57us/step - loss: 0.5000\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 57us/step - loss: 0.5000\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 64us/step - loss: 0.5000\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 62us/step - loss: 0.5000\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 60us/step - loss: 0.5000\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: 0.5000\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: 0.5000\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: 0.5000\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 52us/step - loss: 0.5000\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 0.5000\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 51us/step - loss: 0.5000\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 61us/step - loss: 0.5000\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 0.5000\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: 0.5000\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 70us/step - loss: 0.5000\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 82us/step - loss: 0.5000\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 73us/step - loss: 0.5000\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 58us/step - loss: 0.5000\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 42us/step - loss: 0.5000\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 39us/step - loss: 0.5000\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 42us/step - loss: 0.5000\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 40us/step - loss: 0.5000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 41us/step - loss: 0.5000\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 39us/step - loss: 0.5000\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 44us/step - loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# import optimizer\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# early callbacks definition\n",
    "# optimization will automatically stop when it is no longer helpful\n",
    "early_stop_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# list of learning rates\n",
    "lr_test = [.001, .01, 1]\n",
    "for lr in lr_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    # import the model\n",
    "    model1 = nn_model()\n",
    "    model2 = nn_model2()\n",
    "    # define optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    # compile the model\n",
    "    model1.compile(optimizer=my_optimizer, loss='mean_squared_error')\n",
    "    model2.compile(optimizer=my_optimizer, loss='mean_squared_error')    \n",
    "    # fit the model\n",
    "    model1_fit = model1.fit(X, target, \n",
    "              validation_split=3,\n",
    "              # note that callbacks receives a list\n",
    "              callbacks=[early_stop_monitor],\n",
    "              epochs=30\n",
    "             )\n",
    "    model2_fit = model2.fit(X, target, \n",
    "          validation_split=3,\n",
    "          # note that callbacks receives a list\n",
    "          callbacks=[early_stop_monitor],\n",
    "          epochs=30\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.plot(model1_fit.history['loss'], 'r', model2_fit.history['loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataAnalysis",
   "language": "python",
   "name": "dataanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
